# ðŸ“ˆ PrevisÃ£o de Fechamento de AÃ§Ãµes com LSTM e FastAPI

Este projeto Ã© o resultado do **Tech Challenge da Fase 4 da PÃ³s-Tech MLET FIAP**, cujo desafio consistia em desenvolver uma pipeline completa de **Deep Learning com LSTM** para prever o valor de fechamento de aÃ§Ãµes de uma empresa Ã  escolha, fazer o **deploy do modelo** e disponibilizÃ¡-lo via **API** em produÃ§Ã£o.

## ðŸ’¼ Desafio proposto (resumo)
De acordo com o documento oficial [Pos_Tech_Fase4.pdf], os requisitos incluÃ­am:
- Coletar e prÃ©-processar dados histÃ³ricos de aÃ§Ãµes
- Construir e treinar um modelo preditivo com LSTM
- Salvar o modelo treinado para inferÃªncia
- Fazer o deploy com **SageMaker**
- Disponibilizar uma API RESTful (FastAPI ou Flask)
- Monitorar a performance do modelo com **Amazon CloudWatch**

---

## ðŸ” Pipeline de Desenvolvimento

### 1. ðŸ“Š Coleta, PrÃ©-processamento e Treinamento (`criacao_modelo.ipynb`)

#### ðŸ“¥ Coleta de dados com `yfinance`

Utilizamos a biblioteca `yfinance` para coletar dados da aÃ§Ã£o **ITUB4.SA**, considerando um intervalo de aproximadamente 5 anos:

```python
ACAO = 'ITUB'            # SÃ­mbolo da empresa (ex: 'DIS' para Disney)
START_DATE = '2021-01-01'  # Data de inÃ­cio da coleta de dados
END_DATE = '2025-07-01'    # Data de fim da coleta de dados
SEQUENCE = 60       # NÃºmero de dias passados para prever o prÃ³ximo dia (timestep do LSTM)

df = yf.download(ACAO, start=START_DATE, end=END_DATE)
```

---

#### âš™ï¸ NormalizaÃ§Ã£o e separaÃ§Ã£o dos dados

Os dados foram normalizados com `MinMaxScaler` e divididos em conjuntos de treino e teste com base em uma janela de 60 dias:

```python
def create_sequences(dataset, seq_len):
    X, y = [], []
    for i in range(len(dataset) - seq_len):
        X.append(dataset[i:(i + seq_len), 0])
        y.append(dataset[i + seq_len, 0])
    return np.array(X), np.array(y)

X, y = create_sequences(scaled_data, SEQUENCE)

train_size = int(len(X) * 0.8) # 80/20
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Reshape dos dados para o formato esperado pelo LSTM: [samples, timesteps, features]
# Onde features Ã© 1 porque estamos usando apenas a coluna 'Close'
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
```

---

#### ðŸ§  CriaÃ§Ã£o do modelo LSTM

O modelo foi criado com `Keras` utilizando 2 camadas LSTM e uma camada densa de saÃ­da:

```python
model = Sequential()
# Primeira camada LSTM: retorna sequÃªncias para a prÃ³xima camada LSTM
model.add(LSTM(units=50, return_sequences=True, input_shape=(SEQUENCE, 1)))
model.add(Dropout(0.2)) # 20% dos neurÃ´nios sÃ£o desativados aleatoriamente para regularizaÃ§Ã£o

# Segunda camada LSTM: nÃ£o retorna sequÃªncias, pois Ã© a Ãºltima camada LSTM antes da camada de saÃ­da
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2)) # Mais dropout para regularizaÃ§Ã£o

# Camada de saÃ­da densa: um Ãºnico neurÃ´nio para prever o preÃ§o de fechamento
model.add(Dense(units=1))

# Compilar o modelo:
model.compile(optimizer='adam', loss='mean_squared_error')

# Exibir um resumo da arquitetura do modelo
model.summary()
```

---

#### ðŸ§  Treinamento do modelo LSTM

```python
history = model.fit(
    X_train, y_train,
    epochs=50,           # NÃºmero de Ã©pocas (ajuste conforme necessÃ¡rio)
    batch_size=32,       # Tamanho do lote (ajuste conforme necessÃ¡rio)
    validation_split=0.1, # 10% dos dados de treino serÃ£o usados para validaÃ§Ã£o durante o treinamento
    verbose=1            # Exibir progresso do treinamento
)
```
#### ðŸ“Š AvaliaÃ§Ã£o com mÃ©tricas MAE, RMSE e MAPE

ApÃ³s treinar o modelo, realizamos a previsÃ£o no conjunto de teste e avaliamos as mÃ©tricas de erro:

```python
# Inverter a normalizaÃ§Ã£o para obter os valores reais dos preÃ§os
predictions = scaler.inverse_transform(predictions_scaled)
y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Calcular mÃ©tricas de avaliaÃ§Ã£o
mae = mean_absolute_error(y_test_unscaled, predictions)
rmse = math.sqrt(mean_squared_error(y_test_unscaled, predictions))

# Calcular MAPE (Mean Absolute Percentage Error)
mape = np.mean(np.abs((y_test_unscaled - predictions) / y_test_unscaled)) * 100

print(f"MÃ©tricas de AvaliaÃ§Ã£o no Conjunto de Teste:")
print(f"  MAE (Mean Absolute Error): {mae:.2f}")
print(f"  RMSE (Root Mean Square Error): {rmse:.2f}")
print(f"  MAPE (Mean Absolute Percentage Error): {mape}%")
```

Essas mÃ©tricas nos ajudaram a entender a precisÃ£o e o comportamento do modelo.

---

### 2. ðŸš€ Deploy no SageMaker (`deploy_modelo.ipynb`)
- Salvamos o modelo em formato `SavedModel` do TensorFlow
- Criamos o endpoint no **Amazon SageMaker**
- Validamos o endpoint com `boto3` usando uma entrada de teste

---

### 3. ðŸ“ˆ Monitoramento com CloudWatch (`dashboard.png`)
Criamos um dashboard no **Amazon CloudWatch** com as seguintes mÃ©tricas:
- UtilizaÃ§Ã£o de Disco, CPU e MemÃ³ria
- Quantidade de InvocaÃ§Ãµes
- LatÃªncia do Modelo
- Taxa de Erros
- RequisiÃ§Ãµes Concorrentes

![Dashboard CloudWatch](https://github.com/pvpauloo/FIAP_PROJECTS_04/blob/main/dashboard.png?raw=true)

---

### 4. ðŸ”Œ API com FastAPI (`API_main.py`)
Desenvolvemos uma API hospedada em instÃ¢ncia EC2 com as seguintes rotas:

#### `GET /`
PÃ¡gina inicial com resumo da API

#### `GET /fechamento/hoje`
Retorna a previsÃ£o do fechamento de **hoje (D+0)** com base nos Ãºltimos 60 dias Ãºteis de fechamento.

#### `GET /fechamento/proximos`
Retorna a previsÃ£o para os **prÃ³ximos 5 dias Ãºteis (D+1 atÃ© D+5)**, fazendo previsÃ£o iterativa.

**Exemplo de chamada do modelo com boto3:**

```python
response = runtime.invoke_endpoint(
    EndpointName=ENDPOINT,
    ContentType="application/json",
    Body=json.dumps(payload),
)
result = json.loads(response["Body"].read())
```

---

## ðŸ”€ Desenho Arquitetura AWS

![Arquitetura](https://github.com/pvpauloo/FIAP_PROJECTS_04/blob/main/aws_arch_img.png?raw=true)

---
## ðŸ“ Estrutura de Arquivos

| Arquivo | DescriÃ§Ã£o |
|--------|-----------|
| `criacao_modelo.ipynb` | ETL, construÃ§Ã£o e avaliaÃ§Ã£o do modelo |
| `deploy_modelo.ipynb` | Deploy e testes com endpoint no SageMaker |
| `dashboard.png` | Captura do painel de monitoramento no CloudWatch |
| `API_main.py` | CÃ³digo da API FastAPI com chamadas ao modelo |
| `Pos_Tech_Fase4.pdf` | Enunciado do desafio proposto |

---

## âœ… ConclusÃ£o

O projeto atendeu todos os requisitos propostos:
- Modelo LSTM funcional com bom desempenho
- Deploy efetivo no SageMaker
- API responsiva com inferÃªncia real
- Monitoramento ativo em produÃ§Ã£o

Este projeto demonstra habilidades prÃ¡ticas em **Machine Learning aplicado a sÃ©ries temporais**, **deploy na nuvem**, e **engenharia de APIs** com observabilidade.

---

> Projeto desenvolvido como parte da PÃ³s-Tech MLET â€“ Fase 4 (FIAP)
